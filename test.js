/**
 * Phase 2 Test - Verifies new audio format support, model management, and download features
 */
const path = require('path');
const fs = require('fs');

const modelPath = './models/tiny';
const audioPath = './tests/fixtures/hello.wav';

// Check prerequisites
if (!fs.existsSync(path.join(modelPath, 'model.bin'))) {
  console.log('‚ö†Ô∏è  Model not found. Download with:');
  console.log('   cd models && git lfs install && git clone --depth 1 https://huggingface.co/Systran/faster-whisper-tiny tiny');
  process.exit(0);
}

if (!fs.existsSync(audioPath)) {
  console.log('‚ö†Ô∏è  Test audio not found:', audioPath);
  process.exit(1);
}

console.log('Loading faster-whisper-node...');
const { 
  Engine, 
  availableModels, 
  formatTimestamp,
  isModelAvailable,
  getModelPath,
  getCacheDir,
  decodeAudio,
  decodeAudioBuffer,
} = require('./index');

// Test 1: availableModels()
console.log('\nüìã Test 1: Available models');
const models = availableModels();
console.log('   Models:', models.join(', '));
if (!models.includes('tiny')) {
  console.error('‚ùå availableModels() should include "tiny"');
  process.exit(1);
}
if (!models.includes('large-v3')) {
  console.error('‚ùå availableModels() should include "large-v3"');
  process.exit(1);
}
console.log('   ‚úÖ Passed');

// Test 2: formatTimestamp()
console.log('\nüìã Test 2: formatTimestamp()');
const ts1 = formatTimestamp(65.5);       // 01:05.500
const ts2 = formatTimestamp(65.5, true); // 00:01:05.500
const ts3 = formatTimestamp(3661.123, true); // 01:01:01.123
console.log(`   formatTimestamp(65.5) = "${ts1}"`);
console.log(`   formatTimestamp(65.5, true) = "${ts2}"`);
console.log(`   formatTimestamp(3661.123, true) = "${ts3}"`);
if (!ts1.includes('01:05')) {
  console.error('‚ùå formatTimestamp(65.5) should format correctly');
  process.exit(1);
}
console.log('   ‚úÖ Passed');

// Test 3: Model management functions
console.log('\nüìã Test 3: Model management functions');
const cacheDir = getCacheDir();
console.log('   Cache dir:', cacheDir);
if (!cacheDir.includes('faster-whisper-node')) {
  console.error('‚ùå getCacheDir() should return proper cache path');
  process.exit(1);
}

const tinyPath = getModelPath('tiny');
console.log('   Tiny model path:', tinyPath);
if (!tinyPath.includes('tiny')) {
  console.error('‚ùå getModelPath() should include model name');
  process.exit(1);
}

// Note: isModelAvailable checks the cache dir, not local ./models
const available = isModelAvailable('tiny');
console.log('   Is tiny available (in cache):', available);
// This will likely be false unless downloaded to cache
console.log('   ‚úÖ Passed');

// Test 4: Basic constructor
console.log('\nüìã Test 4: Engine constructor');
console.log('   Loading model from:', modelPath);
const engine = new Engine(modelPath);
console.log('   Sampling rate:', engine.samplingRate(), 'Hz');
console.log('   Is multilingual:', engine.isMultilingual());
console.log('   Num languages:', engine.numLanguages());
if (engine.samplingRate() !== 16000) {
  console.error('‚ùå Sampling rate should be 16000');
  process.exit(1);
}
console.log('   ‚úÖ Passed');

// Test 5: decodeAudio function
console.log('\nüìã Test 5: decodeAudio function');
const samples = decodeAudio(audioPath);
console.log('   Samples:', samples.length);
console.log('   Duration:', (samples.length / 16000).toFixed(2), 'seconds');
console.log('   Sample range:', Math.min(...samples.slice(0, 100)).toFixed(4), 'to', Math.max(...samples.slice(0, 100)).toFixed(4));
if (samples.length === 0) {
  console.error('‚ùå decodeAudio() should return samples');
  process.exit(1);
}
if (samples.length / 16000 < 0.5) {
  console.error('‚ùå Audio should be at least 0.5 seconds');
  process.exit(1);
}
console.log('   ‚úÖ Passed');

// Test 6: decodeAudioBuffer function
console.log('\nüìã Test 6: decodeAudioBuffer function');
const audioBuffer = fs.readFileSync(audioPath);
const bufferSamples = decodeAudioBuffer(audioBuffer);
console.log('   Samples from buffer:', bufferSamples.length);
if (bufferSamples.length !== samples.length) {
  console.error('‚ùå decodeAudioBuffer should return same samples as decodeAudio');
  process.exit(1);
}
console.log('   ‚úÖ Passed');

// Test 7: Simple transcribe (backward compatible)
console.log('\nüìã Test 7: Simple transcribe (backward compatible)');
const simpleResult = engine.transcribe(audioPath);
console.log('   Result:', simpleResult);
if (typeof simpleResult !== 'string' || simpleResult.trim().length === 0) {
  console.error('‚ùå transcribe() should return non-empty string');
  process.exit(1);
}
console.log('   ‚úÖ Passed');

// Test 8: transcribeFile (new Phase 2 method)
console.log('\nüìã Test 8: transcribeFile (new Phase 2 method)');
const fileResult = engine.transcribeFile(audioPath);
console.log('   Duration:', fileResult.duration.toFixed(2), 'seconds');
console.log('   Language:', fileResult.language);
console.log('   Full text:', fileResult.text);
console.log('   Segments:', fileResult.segments.length);

for (const seg of fileResult.segments) {
  console.log(`     [${formatTimestamp(seg.start)} -> ${formatTimestamp(seg.end)}] ${seg.text}`);
}

if (!fileResult.text || fileResult.segments.length === 0) {
  console.error('‚ùå transcribeFile() should return segments');
  process.exit(1);
}
console.log('   ‚úÖ Passed');

// Test 9: Transcribe with all Phase 2 options
console.log('\nüìã Test 9: Transcribe with all Phase 2 options');
const optionResult = engine.transcribeFile(audioPath, {
  beamSize: 3,
  patience: 1.0,
  temperature: 0.0,
  language: 'en',
  initialPrompt: 'This is a test.',
  suppressBlank: true,
  conditionOnPreviousText: true,
  compressionRatioThreshold: 2.4,
  logProbThreshold: -1.0,
  noSpeechThreshold: 0.6,
});
console.log('   Result:', optionResult.text);
if (typeof optionResult.text !== 'string' || optionResult.text.trim().length === 0) {
  console.error('‚ùå transcribeFile with options should return result');
  process.exit(1);
}
console.log('   ‚úÖ Passed');

// Test 10: Transcribe from buffer with options
console.log('\nüìã Test 10: Transcribe from buffer');
const bufferResult = engine.transcribeBuffer(audioBuffer);
console.log('   Result:', bufferResult.text);
if (typeof bufferResult.text !== 'string' || bufferResult.text.trim().length === 0) {
  console.error('‚ùå transcribeBuffer() should return result with text');
  process.exit(1);
}
console.log('   ‚úÖ Passed');

// Test 11: Transcribe from samples
console.log('\nüìã Test 11: Transcribe from samples');
const samplesResult = engine.transcribeSamples(samples);
console.log('   Result:', samplesResult.text);
if (typeof samplesResult.text !== 'string' || samplesResult.text.trim().length === 0) {
  console.error('‚ùå transcribeSamples() should return result with text');
  process.exit(1);
}
console.log('   ‚úÖ Passed');

// Test 12: Engine.withOptions factory with cacheDir
console.log('\nüìã Test 12: Engine.withOptions factory');
const engine2 = Engine.withOptions(modelPath, {
  device: 'cpu',
  computeType: 'default',
  cpuThreads: 4,
  cacheDir: '/tmp/whisper-cache'
});
const result2 = engine2.transcribe(audioPath);
console.log('   Result:', result2);
if (typeof result2 !== 'string' || result2.trim().length === 0) {
  console.error('‚ùå Engine.withOptions should work');
  process.exit(1);
}
console.log('   ‚úÖ Passed');

// Test 13: Language detection (uses multilingual model internally)
console.log('\nüìã Test 13: Language detection');
// Note: tiny model is not multilingual (tiny.en), so this might fail
try {
  if (engine.isMultilingual()) {
    const langResult = engine.detectLanguage(audioPath);
    console.log('   Detected language:', langResult.language);
    console.log('   Probability:', langResult.probability);
    console.log('   ‚úÖ Passed');
  } else {
    console.log('   ‚ö†Ô∏è  Skipped (model is not multilingual)');
  }
} catch (err) {
  console.log('   ‚ö†Ô∏è  Expected error (non-multilingual model):', err.message);
  console.log('   ‚úÖ Passed (correctly rejected)');
}

console.log('\n‚úÖ All Phase 2 tests passed!');
