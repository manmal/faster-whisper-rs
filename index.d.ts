/* tslint:disable */
/* eslint-disable */

/* auto-generated by NAPI-RS */

/** Transcription segment with timing and confidence information */
export interface Segment {
  /** Segment ID (0-indexed) */
  id: number
  /** Seek position in audio frames */
  seek: number
  /** Start time in seconds */
  start: number
  /** End time in seconds */
  end: number
  /** Transcribed text */
  text: string
  /** Token IDs */
  tokens: Array<number>
  /** Decoding temperature used */
  temperature: number
  /** Average log probability */
  avgLogprob: number
  /** Compression ratio */
  compressionRatio: number
  /** Probability of no speech */
  noSpeechProb: number
}
/** Transcription options */
export interface TranscribeOptions {
  /** Source language (e.g., "en", "de", "fr"). If not set, language is auto-detected. */
  language?: string
  /** Task to perform: "transcribe" or "translate" */
  task?: string
  /** Beam size for beam search (default: 5, set to 1 for greedy search) */
  beamSize?: number
  /** Beam search patience factor (default: 1.0) */
  patience?: number
  /** Exponential penalty applied to length during beam search (default: 1.0) */
  lengthPenalty?: number
  /** Penalty for repetition (default: 1.0, set > 1 to penalize) */
  repetitionPenalty?: number
  /** Prevent repetitions of ngrams with this size (default: 0, disabled) */
  noRepeatNgramSize?: number
  /** Sampling temperature (default: 1.0) */
  temperature?: number
  /** Suppress blank outputs at beginning (default: true) */
  suppressBlank?: boolean
  /** Maximum generation length (default: 448) */
  maxLength?: number
  /** Include timestamps in output (default: false) */
  wordTimestamps?: boolean
}
/** Model configuration options */
export interface ModelOptions {
  /** Device to use: "cpu" or "cuda" (default: "cpu") */
  device?: string
  /** Compute type: "default", "auto", "int8", "int8_float16", "int16", "float16", "float32" */
  computeType?: string
  /** Number of CPU threads per replica (0 for auto) */
  cpuThreads?: number
}
/** Transcription result containing all segments and metadata */
export interface TranscriptionResult {
  /** All transcribed segments */
  segments: Array<Segment>
  /** Detected or specified language */
  language: string
  /** Language detection probability (0 if language was specified) */
  languageProbability: number
  /** Total audio duration in seconds */
  duration: number
  /** Full transcribed text (all segments joined) */
  text: string
}
/** Get list of supported model size aliases */
export declare function availableModels(): Array<string>
/** Format seconds to timestamp string (HH:MM:SS.mmm or MM:SS.mmm) */
export declare function formatTimestamp(seconds: number, alwaysIncludeHours?: boolean | undefined | null): string
export declare class Engine {
  /** Create a new transcription engine from a model path */
  constructor(modelPath: string)
  /** Create a new transcription engine with options */
  static withOptions(modelPath: string, options?: ModelOptions | undefined | null): Engine
  /** Transcribe audio file and return structured segments */
  transcribeSegments(audioPath: string, options?: TranscribeOptions | undefined | null): TranscriptionResult
  /** Simple transcription returning just the text (backward compatible) */
  transcribe(audioFile: string): string
  /** Transcribe with options, returning just the text */
  transcribeWithOptions(audioFile: string, options: TranscribeOptions): string
  /** Transcribe from a Buffer containing WAV audio data */
  transcribeBuffer(buffer: Buffer, options?: TranscribeOptions | undefined | null): TranscriptionResult
  /** Transcribe from raw Float32Array samples (must be 16kHz mono, normalized to [-1, 1]) */
  transcribeSamples(samples: Array<number>, options?: TranscribeOptions | undefined | null): TranscriptionResult
  /** Get the expected sampling rate (16000 Hz for Whisper) */
  samplingRate(): number
  /** Check if the model is multilingual */
  isMultilingual(): boolean
  /** Get the number of supported languages */
  numLanguages(): number
}
